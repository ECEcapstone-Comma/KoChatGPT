{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "zsEGLkE77Mio",
        "DD6cVKWy-89m"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# KoChatGPT"
      ],
      "metadata": {
        "id": "sg8Peauy1r1c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터를 사용하여 사전 학습된 대규모 언어 모델을 fine-tuning해 텍스트 생성 모델을 구축\n",
        "\n",
        "* requirements  \n",
        "데이터(RLHF): data_kochatgpt  \n",
        "LLM 모델: GPT2  \n",
        "GPU: Colab  "
      ],
      "metadata": {
        "id": "WXItbRFy2jaU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data 전처리"
      ],
      "metadata": {
        "id": "NouE-yBT3UqD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt: Prompt는 GPT 모델에 입력되는 텍스트로, 모델이 이를 기반으로 응답을 생성. \n",
        "\n",
        "Completion: Completion은 GPT 모델의 응답으로 생성되는 텍스트.  \n",
        "오디션 정보를 기반으로 GPT 모델이 생성할 정보 요소를 completion에 포함.\n",
        "\n",
        "Prompt와 Completion 키를 사용하여 json 파일 생성"
      ],
      "metadata": {
        "id": "7-Hguqra3YIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gafCGjTN7R3B",
        "outputId": "29cb31a5-e76d-4802-9fd0-b3ebf00995e4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SpsTJDebzpFm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/ECE/data.csv')\n",
        "df.info()"
      ],
      "metadata": {
        "id": "QrqzLtJlFpSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['prompt'] = (\n",
        "    '오디션 명 : ' + df['오디션 명'] + '\\r\\n'+\n",
        "    '오디션 내용 : ' + df['상세정보']\n",
        "    \n",
        ")\n",
        "\n",
        "df['completion'] = (\n",
        "    '기획사 명 : ' + df['기획사 명'] + ', '+\n",
        "    '분야 : ' + df['분야'] + ', ' +\n",
        "    '시작 나이 : ' + df['시작 나이']+ ', ' +\n",
        "    '끝 나이 : ' + df['끝 나이']+ ', ' +\n",
        "    '성별 : ' + df['성별'] + ', ' +\n",
        "    '접수 마감일: ' + df['접수 마감일']\n",
        ")\n",
        "\n",
        "df[['prompt', 'completion']].to_csv('/content/drive/MyDrive/ECE/0523/data2.csv', index=False)"
      ],
      "metadata": {
        "id": "AmJZL20xzx3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check  = pd.read_csv('/content/drive/MyDrive/ECE/data2.csv')\n",
        "check"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "syUfaOEc0rXz",
        "outputId": "0c792925-faa6-4b17-f748-576340b961f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                prompt  \\\n",
              "0    오디션 명 : JYP 2023년 5월 셋째주 센터오디션\\r\\n오디션 내용 : 202...   \n",
              "1    오디션 명 : 2023.05 YG MONTHLY AUDITION\\r\\n오디션 내용 ...   \n",
              "2    오디션 명 : 미스틱스토리 온라인 오디션(2023년 5월)\\r\\n오디션 내용 : 미...   \n",
              "3    오디션 명 : JYP 2023년 5월 첫째주 센터오디션\\r\\n오디션 내용 : 202...   \n",
              "4    오디션 명 : FNC 엔터테인먼트 2023년 5월 공개 오디션\\r\\n오디션 내용 :...   \n",
              "..                                                 ...   \n",
              "271  오디션 명 : 쏘스뮤직 7 8월 공개오디션 격변의 전국투어(전국 일정)\\r\\n오디션...   \n",
              "272  오디션 명 : 폴라리스주니어 인스타그램 온라인 오디션\\r\\n오디션 내용 : 안녕하세...   \n",
              "273  오디션 명 : 2021 MLD TOUCH AUDITION\\r\\n오디션 내용 : 20...   \n",
              "274  오디션 명 : Polaris junior 프로젝트 1번째 공개오디션\\r\\n오디션 내...   \n",
              "275  오디션 명 : 2018 애스토리 엔터테인먼트 전국 오디션\\r\\n오디션 내용 : ▶지...   \n",
              "\n",
              "                                            completion  \n",
              "0    기획사 명 : JYP 엔터테인먼트, 분야 : 보컬, 랩, 댄스, 연기, 모델, 시작...  \n",
              "1    기획사 명 : YG 엔터테인먼트, 분야 : 보컬,랩,댄스,기타, 시작 나이 : 20...  \n",
              "2    기획사 명 : 미스틱 스토리, 분야 : 보컬,연기,작사·작곡·프로듀서,기타, 시작 ...  \n",
              "3    기획사 명 : JYP 엔터테인먼트, 분야 : 보컬,랩,댄스,연기,모델, 시작 나이 ...  \n",
              "4    기획사 명 : FNC 엔터테인먼트, 분야 : 보컬,랩,댄스,연기,기타, 시작 나이 ...  \n",
              "..                                                 ...  \n",
              "271  기획사 명 : 쏘스뮤직, 분야 : 보컬,랩,댄스, 시작 나이 : 20,012,002...  \n",
              "272  기획사 명 : 폴라리스 엔터테인먼트, 분야 : 보컬,랩,댄스,연기,기타, 시작 나이...  \n",
              "273  기획사 명 : MLD 엔터테인먼트, 분야 : 보컬,랩,댄스,연기,모델, 시작 나이 ...  \n",
              "274  기획사 명 : 폴라리스 엔터테인먼트, 분야 : 보컬,랩,댄스,연기,기타, 시작 나이...  \n",
              "275  기획사 명 : 애스토리 엔터테인먼트, 분야 : 보컬,랩,댄스.연기,기타, 시작 나이...  \n",
              "\n",
              "[276 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f211c4bf-d449-4804-b01e-47a95e5b7123\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>completion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>오디션 명 : JYP 2023년 5월 셋째주 센터오디션\\r\\n오디션 내용 : 202...</td>\n",
              "      <td>기획사 명 : JYP 엔터테인먼트, 분야 : 보컬, 랩, 댄스, 연기, 모델, 시작...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>오디션 명 : 2023.05 YG MONTHLY AUDITION\\r\\n오디션 내용 ...</td>\n",
              "      <td>기획사 명 : YG 엔터테인먼트, 분야 : 보컬,랩,댄스,기타, 시작 나이 : 20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>오디션 명 : 미스틱스토리 온라인 오디션(2023년 5월)\\r\\n오디션 내용 : 미...</td>\n",
              "      <td>기획사 명 : 미스틱 스토리, 분야 : 보컬,연기,작사·작곡·프로듀서,기타, 시작 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>오디션 명 : JYP 2023년 5월 첫째주 센터오디션\\r\\n오디션 내용 : 202...</td>\n",
              "      <td>기획사 명 : JYP 엔터테인먼트, 분야 : 보컬,랩,댄스,연기,모델, 시작 나이 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>오디션 명 : FNC 엔터테인먼트 2023년 5월 공개 오디션\\r\\n오디션 내용 :...</td>\n",
              "      <td>기획사 명 : FNC 엔터테인먼트, 분야 : 보컬,랩,댄스,연기,기타, 시작 나이 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>오디션 명 : 쏘스뮤직 7 8월 공개오디션 격변의 전국투어(전국 일정)\\r\\n오디션...</td>\n",
              "      <td>기획사 명 : 쏘스뮤직, 분야 : 보컬,랩,댄스, 시작 나이 : 20,012,002...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272</th>\n",
              "      <td>오디션 명 : 폴라리스주니어 인스타그램 온라인 오디션\\r\\n오디션 내용 : 안녕하세...</td>\n",
              "      <td>기획사 명 : 폴라리스 엔터테인먼트, 분야 : 보컬,랩,댄스,연기,기타, 시작 나이...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>오디션 명 : 2021 MLD TOUCH AUDITION\\r\\n오디션 내용 : 20...</td>\n",
              "      <td>기획사 명 : MLD 엔터테인먼트, 분야 : 보컬,랩,댄스,연기,모델, 시작 나이 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>오디션 명 : Polaris junior 프로젝트 1번째 공개오디션\\r\\n오디션 내...</td>\n",
              "      <td>기획사 명 : 폴라리스 엔터테인먼트, 분야 : 보컬,랩,댄스,연기,기타, 시작 나이...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275</th>\n",
              "      <td>오디션 명 : 2018 애스토리 엔터테인먼트 전국 오디션\\r\\n오디션 내용 : ▶지...</td>\n",
              "      <td>기획사 명 : 애스토리 엔터테인먼트, 분야 : 보컬,랩,댄스.연기,기타, 시작 나이...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>276 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f211c4bf-d449-4804-b01e-47a95e5b7123')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f211c4bf-d449-4804-b01e-47a95e5b7123 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f211c4bf-d449-4804-b01e-47a95e5b7123');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_in = '/content/drive/MyDrive/ECE/data2.csv'\n",
        "prompt_out = '/content/drive/MyDrive/ECE/prompt.csv'\n",
        "\n",
        "import csv\n",
        "import random\n",
        "data = []\n",
        "\n",
        "with open(prompt_in, 'r', encoding='utf-8') as file:\n",
        "    reader = csv.reader(file)\n",
        "    for row in reader:\n",
        "        data.append(row[0])\n",
        "\n",
        "with open(prompt_out, 'w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"prompt\"])  \n",
        "\n",
        "    for row in data[1:]:\n",
        "        lines = row.split('\\n')\n",
        "        writer.writerow([row]) \n",
        "        for _ in range(9):\n",
        "            random.shuffle(lines)\n",
        "            prompt = '\\n'.join(lines)\n",
        "            writer.writerow([prompt])  "
      ],
      "metadata": {
        "id": "U_TZ5Fhy5AbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "실행 x"
      ],
      "metadata": {
        "id": "yxc1AOImuI6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['prompt'] = (\n",
        "    df['prompt'] + '\\r\\n\\r\\n'+\n",
        "    '기획사 명은? 모집 분야는? 나이에 대한 조건 중 시작 나이는? 나이에 대한 조건 중 끝 나이는? 성별 조건은? 접수 마감일은?' + '\\r\\n\\r\\n' +\n",
        "    '질문에 대한 답 형식은 기획사 명 : , 분야 : , 시작 나이 : , 끝 나이 : , 성별 : , 접수 마감일 : yyyy-mm-dd' \n",
        ")\n",
        "\n",
        "df['prompt'].to_csv('/content/drive/MyDrive/ECE/prompt.csv', index=False)"
      ],
      "metadata": {
        "id": "KsPovhVkAHI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_file = '/content/drive/MyDrive/ECE/data2.csv'\n",
        "output_file = '/content/drive/MyDrive/ECE/completion.csv'\n",
        "data = []\n",
        "with open(input_file, 'r', encoding='utf-8') as file:\n",
        "    reader = csv.reader(file)\n",
        "    for row in reader:\n",
        "        data.append([row[1]]) \n",
        "\n",
        "output_data = [data[0]]\n",
        "for row in data[1:]:\n",
        "    for _ in range(10):\n",
        "        output_data.append(row)\n",
        "\n",
        "with open(output_file, 'w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerows(output_data)"
      ],
      "metadata": {
        "id": "xz54U8mz0I18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('/content/drive/MyDrive/ECE/prompt.csv')\n",
        "column1 = df1.iloc[:, 0]\n",
        "\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/ECE/completion.csv')\n",
        "column2 = df2.iloc[:, 0]\n",
        "\n",
        "final_df = pd.DataFrame({\n",
        "    'prompt': column1,\n",
        "    'completion': column2\n",
        "})\n",
        "final_df.to_csv('/content/drive/MyDrive/ECE/final.csv', index=False)"
      ],
      "metadata": {
        "id": "o1PoECVY0Mxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/ECE/final.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "zmns4hqI67hP",
        "outputId": "98599858-c8c8-4e8f-8135-ac2dad132b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 prompt  \\\n",
              "0     오디션 명 : JYP 2023년 5월 셋째주 센터오디션\\n오디션 내용 : 2023년...   \n",
              "1     \\n지원분야: 보컬 / 랩 / 댄스 / 연기 / 모델\\n\\n날짜: 2023년 5월 ...   \n",
              "2     *보컬/랩/댄스/연기/모델 중 한 분야만 지원 가능\\n\\n오디션 명 : JYP 20...   \n",
              "3     We will be waiting for your participation!\\n시간...   \n",
              "4     Date: May 21st, 2023 (SUN)\\n\\n\\n날짜: 2023년 5월 2...   \n",
              "...                                                 ...   \n",
              "2755  \\n\\n7월 29일 일요일 광주 오후 4시 30분 [조이댄스 플러그인뮤직 아카데미 ...   \n",
              "2756  \\n\\n\\n*필수사항 메일제목 [2018 애스토리 전국오디션_이름_출생년도_성별]\\...   \n",
              "2757  7월 21일 토요일 대전 오후 1시 [대전 연기모델 학원(대전댄스보컬) 은행동 3호...   \n",
              "2758  (댄스음원은 휴대폰에 지참 - 아이폰7, 8 기종은 연결잭 필수 지참)\\n\\n\\n\\...   \n",
              "2759  \\n*필수사항 메일제목 [2018 애스토리 전국오디션_이름_출생년도_성별]\\n8월 ...   \n",
              "\n",
              "                                             completion  \n",
              "0     기획사 명 : JYP 엔터테인먼트, 분야 : 보컬, 랩, 댄스, 연기, 모델, 시작...  \n",
              "1     기획사 명 : JYP 엔터테인먼트, 분야 : 보컬, 랩, 댄스, 연기, 모델, 시작...  \n",
              "2     기획사 명 : JYP 엔터테인먼트, 분야 : 보컬, 랩, 댄스, 연기, 모델, 시작...  \n",
              "3     기획사 명 : JYP 엔터테인먼트, 분야 : 보컬, 랩, 댄스, 연기, 모델, 시작...  \n",
              "4     기획사 명 : JYP 엔터테인먼트, 분야 : 보컬, 랩, 댄스, 연기, 모델, 시작...  \n",
              "...                                                 ...  \n",
              "2755  기획사 명 : 애스토리 엔터테인먼트, 분야 : 보컬,랩,댄스.연기,기타, 시작 나이...  \n",
              "2756  기획사 명 : 애스토리 엔터테인먼트, 분야 : 보컬,랩,댄스.연기,기타, 시작 나이...  \n",
              "2757  기획사 명 : 애스토리 엔터테인먼트, 분야 : 보컬,랩,댄스.연기,기타, 시작 나이...  \n",
              "2758  기획사 명 : 애스토리 엔터테인먼트, 분야 : 보컬,랩,댄스.연기,기타, 시작 나이...  \n",
              "2759  기획사 명 : 애스토리 엔터테인먼트, 분야 : 보컬,랩,댄스.연기,기타, 시작 나이...  \n",
              "\n",
              "[2760 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b6a2942-0119-4bad-a0ec-0f4bef2ef016\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>completion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>오디션 명 : JYP 2023년 5월 셋째주 센터오디션\\n오디션 내용 : 2023년...</td>\n",
              "      <td>기획사 명 : JYP 엔터테인먼트, 분야 : 보컬, 랩, 댄스, 연기, 모델, 시작...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\n지원분야: 보컬 / 랩 / 댄스 / 연기 / 모델\\n\\n날짜: 2023년 5월 ...</td>\n",
              "      <td>기획사 명 : JYP 엔터테인먼트, 분야 : 보컬, 랩, 댄스, 연기, 모델, 시작...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>*보컬/랩/댄스/연기/모델 중 한 분야만 지원 가능\\n\\n오디션 명 : JYP 20...</td>\n",
              "      <td>기획사 명 : JYP 엔터테인먼트, 분야 : 보컬, 랩, 댄스, 연기, 모델, 시작...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>We will be waiting for your participation!\\n시간...</td>\n",
              "      <td>기획사 명 : JYP 엔터테인먼트, 분야 : 보컬, 랩, 댄스, 연기, 모델, 시작...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Date: May 21st, 2023 (SUN)\\n\\n\\n날짜: 2023년 5월 2...</td>\n",
              "      <td>기획사 명 : JYP 엔터테인먼트, 분야 : 보컬, 랩, 댄스, 연기, 모델, 시작...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2755</th>\n",
              "      <td>\\n\\n7월 29일 일요일 광주 오후 4시 30분 [조이댄스 플러그인뮤직 아카데미 ...</td>\n",
              "      <td>기획사 명 : 애스토리 엔터테인먼트, 분야 : 보컬,랩,댄스.연기,기타, 시작 나이...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2756</th>\n",
              "      <td>\\n\\n\\n*필수사항 메일제목 [2018 애스토리 전국오디션_이름_출생년도_성별]\\...</td>\n",
              "      <td>기획사 명 : 애스토리 엔터테인먼트, 분야 : 보컬,랩,댄스.연기,기타, 시작 나이...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2757</th>\n",
              "      <td>7월 21일 토요일 대전 오후 1시 [대전 연기모델 학원(대전댄스보컬) 은행동 3호...</td>\n",
              "      <td>기획사 명 : 애스토리 엔터테인먼트, 분야 : 보컬,랩,댄스.연기,기타, 시작 나이...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2758</th>\n",
              "      <td>(댄스음원은 휴대폰에 지참 - 아이폰7, 8 기종은 연결잭 필수 지참)\\n\\n\\n\\...</td>\n",
              "      <td>기획사 명 : 애스토리 엔터테인먼트, 분야 : 보컬,랩,댄스.연기,기타, 시작 나이...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2759</th>\n",
              "      <td>\\n*필수사항 메일제목 [2018 애스토리 전국오디션_이름_출생년도_성별]\\n8월 ...</td>\n",
              "      <td>기획사 명 : 애스토리 엔터테인먼트, 분야 : 보컬,랩,댄스.연기,기타, 시작 나이...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2760 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b6a2942-0119-4bad-a0ec-0f4bef2ef016')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1b6a2942-0119-4bad-a0ec-0f4bef2ef016 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1b6a2942-0119-4bad-a0ec-0f4bef2ef016');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "실행 X"
      ],
      "metadata": {
        "id": "YQilc3ciueyl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import random\n",
        "\n",
        "input_file = '/content/drive/MyDrive/ECE/final.csv'\n",
        "output_file = '/content/drive/MyDrive/ECE/final.csv'\n",
        "\n",
        "data = []\n",
        "\n",
        "with open(input_file, 'r', encoding='utf-8') as file:\n",
        "    reader = csv.reader(file)\n",
        "    for row in reader:\n",
        "        data.append(row)\n",
        "\n",
        "header = data[0]\n",
        "shuffled_data = random.sample(data[1:], len(data[1:]))\n",
        "\n",
        "with open(output_file, 'w', encoding='utf-8', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(header)  \n",
        "    writer.writerows(shuffled_data) "
      ],
      "metadata": {
        "id": "BYknzoRK6uKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "csv_path = '/content/drive/MyDrive/ECE/final.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "data = []\n",
        "for i in range(len(df)):\n",
        "    prompt = df.iloc[i, 0]\n",
        "    completion = df.iloc[i, 1]\n",
        "    \n",
        "    entry = {\n",
        "        \"prompt\": prompt,\n",
        "        \"completion\": completion\n",
        "    }\n",
        "    \n",
        "    data.append(entry)\n",
        "\n",
        "json_data = json.dumps(data)\n",
        "parsed_data = json.loads(json_data)\n",
        "formatted_data = json.dumps(parsed_data, indent=4, ensure_ascii=False)\n",
        "#print(formatted_data[:3000])\n",
        "\n",
        "with open('/content/drive/MyDrive/ECE/data.json', 'w', encoding='utf-8') as file:\n",
        "    json.dump(data, file, indent=4, ensure_ascii=False)"
      ],
      "metadata": {
        "id": "OF7knFnO0Q2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "file_path = \"/content/drive/MyDrive/ECE/data.json\"\n",
        "\n",
        "with open(file_path, \"r\") as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "formatted_data = json.dumps(data, indent=4, sort_keys=False, ensure_ascii=False)\n",
        "print(formatted_data[:3000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pi3T4oA10-M7",
        "outputId": "80e54c7f-518f-42cc-f09f-b3b5a1bcada0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "    {\n",
            "        \"prompt\": \"오디션 명 : JYP 2023년 5월 셋째주 센터오디션\\n오디션 내용 : 2023년 5월 셋째주 센터오디션 안내\\n\\n날짜: 2023년 5월 21일 일요일\\n시간: 오후 1시~4시 (4시 이후 입장 절대 불가)\\n대상: 2001년생~2012년생 / 성별, 국적 제한 없음\\n장소: JYP Center (서울시 강동구 강동대로 205)\\n지원분야: 보컬 / 랩 / 댄스 / 연기 / 모델\\n참여방법: 현장 접수\\n\\n주의사항\\n*신분증 반드시 준비(학생증, 여권, 등본 등) 없을 시 참여 제한\\n*보컬/랩/댄스/연기/모델 중 한 분야만 지원 가능\\n*댄스 지원자는 반드시 휴대폰 음원 지참(CD 및 USB 불가)\\n*팀 지원 가능\\n\\n여러분의 많은 참여 기다리고 있겠습니다.\\n감사합니다.\\n\\n[May, 2023 Second JYP Monthly Audition]\\n\\nDate: May 21st, 2023 (SUN)\\nTime: pm1:00~pm4:00 (No entrance after pm4:00)\\nQualification: Anyone born between 2001~2012 regardless of their gender and nationality\\nPlace: JYP Center (205, Gangdong-daero Gangdong-gu, Seoul)\\nAudition Categories: VOCAL / RAP / DANCE / ACTING / MODEL\\nHow to Apply: Walk-in Registration\\n\\nKeep in Mind\\n*You must bring your ID (ex. passport) to participate\\n*You can only apply for one audition category. (VOCAL/RAP/DANCE/ACTING/MODEL)\\n*Dance applicants must prepare their dance music on their phones. (NO physical CD or USB)\\n*You may apply as a team\\n\\nWe will be waiting for your participation!\\nThank you.\",\n",
            "        \"completion\": \"기획사 명 : JYP 엔터테인먼트, 분야 : 보컬, 랩, 댄스, 연기, 모델, 시작 나이 : 2001, 끝 나이 : 2012, 성별 : 모두, 접수 마감일: 2023-5-21\"\n",
            "    },\n",
            "    {\n",
            "        \"prompt\": \"오디션 내용 : 2023년 5월 셋째주 센터오디션 안내\\n오디션 명 : JYP 2023년 5월 셋째주 센터오디션\\n대상: 2001년생~2012년생 / 성별, 국적 제한 없음\\n참여방법: 현장 접수\\nTime: pm1:00~pm4:00 (No entrance after pm4:00)\\n주의사항\\n\\n*보컬/랩/댄스/연기/모델 중 한 분야만 지원 가능\\n\\n*You can only apply for one audition category. (VOCAL/RAP/DANCE/ACTING/MODEL)\\n지원분야: 보컬 / 랩 / 댄스 / 연기 / 모델\\n*You may apply as a team\\nWe will be waiting for your participation!\\nKeep in Mind\\n*팀 지원 가능\\n*Dance applicants must prepare their dance music on their phones. (NO physical CD or USB)\\n장소: JYP Center (서울시 강동구 강동대로 205)\\nHow to Apply: Walk-in Registration\\n[May, 2023 Second JYP Monthly Audition]\\n시간: 오후 1시~4시 (4시 이후 입장 절대 불가)\\nDate: May 21st, 2023 (SUN)\\nThank you.\\nQualification: Anyone born between 2001~2012 regardless of their gender and nationality\\n*댄스 지원자는 반드시 휴대폰 음원 지참(CD 및 USB 불가)\\n\\n*You must bring your ID (ex. passport) to participate\\n\\n여러분의 많은 참여 기다리고 있겠습니다.\\n\\n*신분증 반드시 준비(학생증, 여권, 등본 등) 없을 시 참여 제한\\n날짜: 2023년 5월 21일 일요일\\n감사합니다.\\n\\nAudition Categories: VOCAL / RAP / DANCE / ACTING / MODEL\\nPlace: JYP Center (205, Gangdong-daero Gangdong-gu, Seoul)\\n\",\n",
            "        \"completion\": \"기획사 명 : JYP 엔터테인먼트, 분야 : 보컬, 랩, 댄스, 연기, 모델, 시작 나이 : 2001, 끝 나이 : 2012, 성별 : 모두, 접수 마감일: 2023-5-21\"\n",
            "    },\n",
            "    {\n",
            "        \"prompt\": \"지원분야: 보컬 / 랩 / 댄스 / 연기 / 모델\\nWe will be waiting for your participation!\\n여러분의 많은 참여 기다리고 있겠습니다.\\n시간: 오후 1시~4시 (4시 이후 입장 절대 불가)\\n\\n오디션 내용 : 2023년 5월 셋째주 센터오디션 안내\\n*You may apply as a team\\nDate: May 21st, 2023 (SUN)\\n참여방법: 현장 접수\\n주의사항\\n\\n\\n오디션 명 : JYP 2023년 5월 셋째주 센터오디션\\n*You can only apply for one audition category. (VOCAL/RAP/DANCE/ACTING/MODEL)\\n대상: 2001년생~2012년생 / 성별, 국적 제한 없음\\n*보컬/랩/댄스/연기/모델 중 한 분야만 지원 가능\\n장소: JYP Center (서울시 강동구 강동대로 205)\\nQualification: Anyone born between 2001~2012 regardless of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## INSTALL"
      ],
      "metadata": {
        "id": "zsEGLkE77Mio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.13.1+cu116 --extra-index-url https://download.pytorch.org/whl/cu116\n",
        "\n",
        "# for transformers, 최신버전은 에러발생\n",
        "!pip install transformers==4.28.1\n",
        "# for ColossalAI\n",
        "!pip install colossalai==0.2.7\n",
        "\n",
        "# setup library\n",
        "!pip install openai\n",
        "!pip install langchain==0.0.113\n",
        "!pip install pandas>=1.4.1\n",
        "\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FNU3Kms6jsN",
        "outputId": "9cf24dfb-4d5f-43d2-ed71-041c6448d3ee"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu116\n",
            "Collecting torch==1.13.1+cu116\n",
            "  Downloading https://download.pytorch.org/whl/cu116/torch-1.13.1%2Bcu116-cp310-cp310-linux_x86_64.whl (1977.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 GB\u001b[0m \u001b[31m384.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1+cu116) (4.5.0)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1+cu118\n",
            "    Uninstalling torch-2.0.1+cu118:\n",
            "      Successfully uninstalled torch-2.0.1+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.13.1+cu116 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1+cu116 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1+cu116 which is incompatible.\n",
            "torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 1.13.1+cu116 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.13.1+cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.28.1\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0 (from transformers==4.28.1)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.28.1)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m110.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.28.1) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.1) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.28.1) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.28.1) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting colossalai==0.2.7\n",
            "  Downloading colossalai-0.2.7.tar.gz (686 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m686.7/686.7 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from colossalai==0.2.7) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from colossalai==0.2.7) (4.65.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from colossalai==0.2.7) (5.9.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from colossalai==0.2.7) (23.1)\n",
            "Collecting pre-commit (from colossalai==0.2.7)\n",
            "  Downloading pre_commit-3.3.2-py2.py3-none-any.whl (202 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.8/202.8 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from colossalai==0.2.7) (13.3.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from colossalai==0.2.7) (8.1.3)\n",
            "Collecting fabric (from colossalai==0.2.7)\n",
            "  Downloading fabric-3.0.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting contexttimer (from colossalai==0.2.7)\n",
            "  Downloading contexttimer-0.3.3.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ninja (from colossalai==0.2.7)\n",
            "  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from colossalai==0.2.7) (1.13.1+cu116)\n",
            "Collecting invoke>=2.0 (from fabric->colossalai==0.2.7)\n",
            "  Downloading invoke-2.1.2-py3-none-any.whl (160 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting paramiko>=2.4 (from fabric->colossalai==0.2.7)\n",
            "  Downloading paramiko-3.1.0-py3-none-any.whl (211 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.2/211.2 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cfgv>=2.0.0 (from pre-commit->colossalai==0.2.7)\n",
            "  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit->colossalai==0.2.7)\n",
            "  Downloading identify-2.5.24-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.8/98.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nodeenv>=0.11.1 (from pre-commit->colossalai==0.2.7)\n",
            "  Downloading nodeenv-1.8.0-py2.py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from pre-commit->colossalai==0.2.7) (6.0)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit->colossalai==0.2.7)\n",
            "  Downloading virtualenv-20.23.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->colossalai==0.2.7) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->colossalai==0.2.7) (2.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->colossalai==0.2.7) (4.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->colossalai==0.2.7) (0.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nodeenv>=0.11.1->pre-commit->colossalai==0.2.7) (67.7.2)\n",
            "Collecting bcrypt>=3.2 (from paramiko>=2.4->fabric->colossalai==0.2.7)\n",
            "  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (593 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.7/593.7 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=3.3 in /usr/local/lib/python3.10/dist-packages (from paramiko>=2.4->fabric->colossalai==0.2.7) (40.0.2)\n",
            "Collecting pynacl>=1.5 (from paramiko>=2.4->fabric->colossalai==0.2.7)\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distlib<1,>=0.3.6 (from virtualenv>=20.10.0->pre-commit->colossalai==0.2.7)\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock<4,>=3.11 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->colossalai==0.2.7) (3.12.0)\n",
            "Requirement already satisfied: platformdirs<4,>=3.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->colossalai==0.2.7) (3.3.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.3->paramiko>=2.4->fabric->colossalai==0.2.7) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.3->paramiko>=2.4->fabric->colossalai==0.2.7) (2.21)\n",
            "Building wheels for collected packages: colossalai, contexttimer\n",
            "  Building wheel for colossalai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colossalai: filename=colossalai-0.2.7-py3-none-any.whl size=896479 sha256=9c5741850e87903dbe46ed7db73a68807d0a3b7beae422318e68032b96acbb5f\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/85/25/32a3af943ea5ca261b1b51dae74a4629599ce1bc6fe58dbbfc\n",
            "  Building wheel for contexttimer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contexttimer: filename=contexttimer-0.3.3-py3-none-any.whl size=5803 sha256=26c606f117b6072bfa10d5c1e4f3afd64ad917c387b845cab483a8d21b4a946c\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/1c/da/cfd97201d88ccce214427fa84a5caeb91fef7c5a1b4c4312b4\n",
            "Successfully built colossalai contexttimer\n",
            "Installing collected packages: ninja, distlib, contexttimer, virtualenv, nodeenv, invoke, identify, cfgv, bcrypt, pynacl, pre-commit, paramiko, fabric, colossalai\n",
            "Successfully installed bcrypt-4.0.1 cfgv-3.3.1 colossalai-0.2.7 contexttimer-0.3.3 distlib-0.3.6 fabric-3.0.1 identify-2.5.24 invoke-2.1.2 ninja-1.11.1 nodeenv-1.8.0 paramiko-3.1.0 pre-commit-3.3.2 pynacl-1.5.0 virtualenv-20.23.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.7-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp (from openai)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.7 yarl-1.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting langchain==0.0.113\n",
            "  Downloading langchain-0.0.113-py3-none-any.whl (396 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.0/396.0 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML<7,>=6 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.113) (6.0)\n",
            "Collecting SQLAlchemy<2,>=1 (from langchain==0.0.113)\n",
            "  Downloading SQLAlchemy-1.4.48-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.113) (3.8.4)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain==0.0.113)\n",
            "  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.113) (1.22.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.113) (1.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.113) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.113) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.113) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.113) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.113) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.113) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.113) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.113) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.113) (1.3.1)\n",
            "Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.113)\n",
            "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.113)\n",
            "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Collecting typing-inspect>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.113)\n",
            "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain==0.0.113) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.113) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.113) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.113) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2,>=1->langchain==0.0.113) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.113) (23.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.113)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: SQLAlchemy, mypy-extensions, marshmallow, typing-inspect, marshmallow-enum, dataclasses-json, langchain\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.10\n",
            "    Uninstalling SQLAlchemy-2.0.10:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.10\n",
            "Successfully installed SQLAlchemy-1.4.48 dataclasses-json-0.5.7 langchain-0.0.113 marshmallow-3.19.0 marshmallow-enum-1.5.1 mypy-extensions-1.0.0 typing-inspect-0.8.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Collecting responses<0.19 (from datasets)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, responses, multiprocess, datasets\n",
            "Successfully installed datasets-2.12.0 dill-0.3.6 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## import"
      ],
      "metadata": {
        "id": "DD6cVKWy-89m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from datasets import load_dataset\n",
        "import transformers\n",
        "import pandas as pd\n",
        "import argparse\n",
        "import json\n",
        "import copy\n",
        "import logging\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from transformers import Trainer, TrainingArguments, AutoModelWithLMHead\n",
        "from dataclasses import dataclass"
      ],
      "metadata": {
        "id": "QTKj7gIS_Mel"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import\n",
        "#import os\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "#import torch\n",
        "#import torch.nn as nn\n",
        "#from torch.utils.data import Dataset\n",
        "#from datasets import load_dataset\n",
        "#import transformers\n",
        "#from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM, pipeline\n",
        "#from transformers import Trainer, TrainingArguments, AutoModelWithLMHead\n",
        "from copy import deepcopy\n",
        "from torch.optim import Adam\n",
        "from transformers import AutoTokenizer, BloomTokenizerFast\n",
        "from transformers.models.gpt2.tokenization_gpt2 import GPT2Tokenizer\n",
        "#import pandas as pd\n",
        "#import argparse\n",
        "#import copy\n",
        "#import logging\n",
        "#import json\n",
        "#from dataclasses import dataclass, field"
      ],
      "metadata": {
        "id": "QHSSbWLZ-9_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Torch version:{}\".format(torch.__version__))\n",
        "print(\"cuda version: {}\".format(torch.version.cuda))\n",
        "print(\"cudnn version:{}\".format(torch.backends.cudnn.version()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdvkeEzF_K7o",
        "outputId": "25a53c34-a5bf-42c6-8420-083343c1adcf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch version:1.13.1+cu116\n",
            "cuda version: 11.6\n",
            "cudnn version:8302\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## define argment"
      ],
      "metadata": {
        "id": "B1HP_cPX_biE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define argment\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--data_path_1_SFT', type=str, default='/content/drive/MyDrive/ECE/0523/data.json')\n",
        "parser.add_argument('--model_name', type=str, default='gpt2')\n",
        "parser.add_argument('--max_epochs', type=int, default=2)\n",
        "parser.add_argument('--train_batch_size', type=int, default=8)\n",
        "parser.add_argument('--output_dir', type=str, default='/content/drive/MyDrive/ECE/0523/output_1_SFT')\n",
        "\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "# for test\n",
        "args.model_name = 'skt/kogpt2-base-v2'  # SK GPT2, https://github.com/SKT-AI/KoGPT2\n",
        "# args.model_name = 'ajoublue-gpt2-base'  # 아주대, https://github.com/HeegyuKim/language-model\n",
        "args.max_epochs = 2\n",
        "print(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qz4cFwz__Ztd",
        "outputId": "dc19b6b3-38fe-45d1-fe45-9635eb660ff2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(data_path_1_SFT='/content/drive/MyDrive/ECE/0523/data.json', model_name='skt/kogpt2-base-v2', max_epochs=2, train_batch_size=8, output_dir='/content/drive/MyDrive/ECE/0523/output_1_SFT')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## data load & config"
      ],
      "metadata": {
        "id": "VSlAEeEs_uD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data config\n",
        "IGNORE_INDEX = -100\n",
        "DEFAULT_PAD_TOKEN = \"[PAD]\"\n",
        "DEFAULT_EOS_TOKEN = \"</s>\"\n",
        "DEFAULT_BOS_TOKEN = \"</s>\"\n",
        "DEFAULT_UNK_TOKEN = \"</s>\"\n",
        "PROMPT_DICT = {\n",
        "    \"prompt_no_input\": (\n",
        "        \"### Instruction(명령어):\\n {prompt} \\n\\n\\n\\n ###  Response(응답) \\n\"\n",
        "    ),\n",
        "}"
      ],
      "metadata": {
        "id": "ZBupGTvy_qz0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# JSON 파일 경로\n",
        "json_file_path = \"/content/drive/MyDrive/ECE/data.json\"\n",
        "\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
        "    args.model_name,\n",
        "    padding_side=\"right\",\n",
        "    model_max_length=1024,    \n",
        ")\n",
        "\n",
        "\n",
        "with open(json_file_path, \"r\") as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# 가장 긴 prompt 찾기\n",
        "max_length = 0\n",
        "max_prompt = \"\"\n",
        "\n",
        "for entry in data:\n",
        "    prompt = entry[\"prompt\"]\n",
        "    prompt_length = len(prompt)\n",
        "    if prompt_length > max_length:\n",
        "        max_length = prompt_length\n",
        "        max_prompt = prompt\n",
        "\n",
        "print(\"가장 긴 Prompt의 길이:\", max_length)\n",
        "\n",
        "tokens = tokenizer.tokenize(max_prompt)\n",
        "num_tokens = len(tokens)\n",
        "print(\"최대 토큰 수 : \", num_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAQ1gxSp7rQu",
        "outputId": "cdd7332b-56a4-4daa-c13c-47de9996117c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "가장 긴 Prompt의 길이: 1801\n",
            "최대 토큰 수 :  927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_json(file_path):\n",
        "    try:\n",
        "        with open(file_path, \"r\") as json_file:\n",
        "            data = json.load(json_file)\n",
        "            if not isinstance(data, list):\n",
        "                print(\"Error: JSON 파일의 최상위 객체는 리스트 형태여야 합니다.\")\n",
        "                return False\n",
        "            for item in data:\n",
        "                if not isinstance(item, dict):\n",
        "                    print(\"Error: JSON 파일의 각 아이템은 딕셔너리 형태여야 합니다.\")\n",
        "                    return False\n",
        "                if \"prompt\" not in item or \"completion\" not in item:\n",
        "                    print(\"Error: JSON 파일의 각 아이템은 'prompt'와 'completion' 키를 가져야 합니다.\")\n",
        "                    return False\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: JSON 파일이 존재하지 않습니다.\")\n",
        "        return False\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"Error: JSON 파일의 형식이 올바르지 않습니다.\")\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n",
        "json_file_path = \"/content/drive/MyDrive/ECE/data.json\"\n",
        "is_valid = validate_json(json_file_path)\n",
        "\n",
        "if is_valid:\n",
        "    print(\"JSON 파일의 구성이 올바르게 확인되었습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2Y0KRDj_8od",
        "outputId": "592d1a26-d2fb-4309-e2ed-af0d6f34dc4f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSON 파일의 구성이 올바르게 확인되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model preparation"
      ],
      "metadata": {
        "id": "hWT-Wdc5B6ei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 모델 준비\n",
        "model = AutoModelForCausalLM.from_pretrained(args.model_name)\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
        "    args.model_name,\n",
        "    padding_side=\"right\",\n",
        "    model_max_length=512,    \n",
        ")\n",
        "tokenizer.add_special_tokens(\n",
        "    {\n",
        "        \"eos_token\": DEFAULT_EOS_TOKEN,\n",
        "        \"bos_token\": DEFAULT_BOS_TOKEN,\n",
        "        \"unk_token\": DEFAULT_UNK_TOKEN,\n",
        "    }\n",
        ")    \n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "print(tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPYtWwoUB4fZ",
        "outputId": "1e9525fd-716f-4af7-dfd3-f4bd80293974"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2TokenizerFast(name_or_path='skt/kogpt2-base-v2', vocab_size=51200, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '</s>', 'eos_token': '</s>', 'unk_token': '</s>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare data"
      ],
      "metadata": {
        "id": "MdF4_sWAC3W2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "source and target 생성  \n",
        "prompt_no_input 이용하여 source 생성  \n",
        "pattern_output 이용하여 target 생성  \n",
        "  \n",
        "tokenization  \n",
        "소스와 타겟을 토큰화하여 모델 입력 형식에 맞게 변환.  \n",
        "_tokenize_fn 메서드를 사용  \n",
        "토큰화된 소스는 sources_tokenized에 저장되고,  \n",
        "토큰화된 소스와 타겟을 합친 예제는 examples_tokenized에 저장  \n",
        "  \n",
        "입력과 레이블 생성  \n",
        "소스와 타겟을 이용하여 입력(input)과 레이블(labels)을 생성  \n",
        "input : 토큰화된 예제에서 소스만 추출  \n",
        "labels : 토큰화된 예제 전체를 복사한 후 소스의 길이만큼 -100 값으로 채움  \n",
        "  \n",
        "dataset 구성 입력(input_ids)과 레이블(labels)을 데이터셋 객체에 저장  "
      ],
      "metadata": {
        "id": "UUVQqMTZC59H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## prepare data\n",
        "from typing import Optional, Dict, Sequence\n",
        "    \n",
        "class SFT_dataset(Dataset):\n",
        "    def __init__(self, data_path_1_SFT: str, tokenizer: transformers.PreTrainedTokenizer, verbose=False):\n",
        "        super(SFT_dataset, self).__init__()\n",
        "        logging.warning(\"Loading data...\")\n",
        "        \n",
        "        ## format\n",
        "        pattern_instruction = 'prompt'  # instruction\n",
        "        pattern_output = 'completion'  # output\n",
        "\n",
        "        ## load dataset\n",
        "        data_path_1_SFT = '/content/drive/MyDrive/ECE/data.json'\n",
        "        with open(data_path_1_SFT, \"r\", encoding='utf-8-sig') as json_file:\n",
        "            list_data_dict = json.load(json_file)\n",
        "            if verbose:\n",
        "                print('## data check ##')\n",
        "                print((list_data_dict[0]))     \n",
        "\n",
        "        ## 데이터셋 만들기, source와 target\n",
        "        prompt_no_input = PROMPT_DICT[\"prompt_no_input\"]  # 템플릿 가져오기\n",
        "\n",
        "        # 입력\n",
        "        sources = []\n",
        "        for example in list_data_dict:\n",
        "          tmp = prompt_no_input.format_map(example)\n",
        "          sources.append(tmp)\n",
        "\n",
        "        # 출력\n",
        "        targets = []\n",
        "        for example in list_data_dict:\n",
        "            targets.append(f\"{example[pattern_output]}{tokenizer.eos_token}\")\n",
        "\n",
        "        if verbose:\n",
        "            idx = 0\n",
        "            print((sources[idx]))\n",
        "            print((targets[idx]))\n",
        "\n",
        "        examples = [s + t for s, t in zip(sources, targets)]\n",
        "\n",
        "        # source data tokenized\n",
        "        sources_tokenized = self._tokenize_fn(sources, tokenizer)  # source만\n",
        "        examples_tokenized = self._tokenize_fn(examples, tokenizer)  # source + target\n",
        "\n",
        "\n",
        "        ## 입력은 source, 출력은 source+target 이지만 학습은 target 부분만\n",
        "        input_ids = examples_tokenized[\"input_ids\"]\n",
        "        labels = copy.deepcopy(input_ids)\n",
        "        for label, source_len in zip(labels, sources_tokenized[\"input_ids_lens\"]):\n",
        "            label[:source_len] = IGNORE_INDEX  # source 부분은 -100으로 채운다\n",
        "\n",
        "        data_dict = dict(input_ids=input_ids, labels=labels)        \n",
        "        \n",
        "        self.input_ids = data_dict[\"input_ids\"]\n",
        "        self.labels = data_dict[\"labels\"]\n",
        "        logging.warning(\"Loading data done!!: %d\"%(len(self.labels)))    \n",
        "        \n",
        "    def _tokenize_fn(self, strings: Sequence[str], tokenizer: transformers.PreTrainedTokenizer) -> Dict:\n",
        "        tokenized_list = [\n",
        "            tokenizer(\n",
        "                text,\n",
        "                return_tensors=\"pt\",\n",
        "                padding=\"longest\",\n",
        "                max_length=tokenizer.model_max_length,\n",
        "                truncation=True,\n",
        "            )\n",
        "            for text in strings\n",
        "        ]\n",
        "        input_ids = labels = [tokenized.input_ids[0] for tokenized in tokenized_list]\n",
        "        input_ids_lens = labels_lens = [\n",
        "            tokenized.input_ids.ne(tokenizer.pad_token_id).sum().item() for tokenized in tokenized_list\n",
        "        ]\n",
        "        return dict(\n",
        "            input_ids=input_ids,\n",
        "            labels=labels,\n",
        "            input_ids_lens=input_ids_lens,\n",
        "            labels_lens=labels_lens,\n",
        "        )        \n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    \n",
        "    def __getitem__(self, i) -> Dict[str, torch.Tensor]:\n",
        "        return dict(input_ids=self.input_ids[i], labels=self.labels[i])\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorForSupervisedDataset(object):\n",
        "    \"\"\"Collate examples for supervised fine-tuning.\"\"\"\n",
        "\n",
        "    tokenizer: transformers.PreTrainedTokenizer\n",
        "\n",
        "    def __call__(self, instances: Sequence[Dict]) -> Dict[str, torch.Tensor]:\n",
        "        input_ids, labels = tuple([instance[key] for instance in instances] for key in (\"input_ids\", \"labels\"))\n",
        "        input_ids = torch.nn.utils.rnn.pad_sequence(\n",
        "            input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
        "        )\n",
        "        labels = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True, padding_value=IGNORE_INDEX)\n",
        "        return dict(\n",
        "            input_ids=input_ids,\n",
        "            labels=labels,\n",
        "            attention_mask=input_ids.ne(self.tokenizer.pad_token_id),\n",
        "        )\n",
        "\n",
        "  \n",
        "train_dataset = SFT_dataset(data_path_1_SFT=args.data_path_1_SFT, tokenizer=tokenizer)\n",
        "eval_dataset  = None  \n",
        "data_collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uik0gA3WB8Kx",
        "outputId": "6e804d96-1875-4b6e-fe1e-675e4a6ec3e3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Loading data...\n",
            "WARNING:root:Loading data done!!: 2760\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8g-i2N8dDOGV",
        "outputId": "bef46593-cf27-4dbe-eef1-a058e4ac0eeb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.19.0-py3-none-any.whl (219 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->accelerate) (4.5.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_save_model_for_hf_trainer(trainer: transformers.Trainer, output_dir: str):\n",
        "    state_dict = trainer.model.state_dict()\n",
        "    if trainer.args.should_save:\n",
        "        cpu_state_dict = {key: value.cpu() for key, value in list(state_dict.items())}\n",
        "        del state_dict\n",
        "        trainer._save(output_dir, state_dict=cpu_state_dict)  # noqa"
      ],
      "metadata": {
        "id": "54pZcxusEUaE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RUN"
      ],
      "metadata": {
        "id": "VYzpNYO9EXQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 학습\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/ECE/test\", \n",
        "    overwrite_output_dir=True, \n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=5,\n",
        "    per_device_eval_batch_size=5,\n",
        "    eval_steps=1,\n",
        "    save_steps=500, \n",
        "    warmup_steps=1, \n",
        "    save_total_limit=0,\n",
        "    prediction_loss_only=True,\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    #save_strategy='no',\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.save_state()\n",
        "safe_save_model_for_hf_trainer(trainer=trainer, output_dir=args.output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "nhKjEjmLDolO",
        "outputId": "8bd02745-5b8f-4c21-ee14-6bd3641e1b69"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2760' max='2760' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2760/2760 31:47, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.211600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.026500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.007500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.001200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 추론 테스트\n",
        "generator = pipeline('text-generation', model=args.output_dir, tokenizer=tokenizer)\n",
        "\n",
        "generation_args = dict(\n",
        "    num_beams=4,\n",
        "    repetition_penalty=2.0,\n",
        "    no_repeat_ngram_size=4,\n",
        "    eos_token_id=375, \n",
        "    max_new_tokens=64,\n",
        "    do_sample=True,\n",
        "    top_k=50,\n",
        "    early_stopping=True\n",
        ")\n",
        "\n",
        "list_prompt = [\"오디션 명 : JYP 2023년 5월 셋째주 센터오디션\\n상세정보 : 2023년 5월 셋째주 센터오디션 안내\\n\\n접수 마감일 : 2023년 5월 21일 일요일\\n시간: 오후 1시~4시 (4시 이후 입장 절대 불가)\\n대상: 2001년생~2012년생 / 성별, 국적 제한 없음\\n장소: JYP Center (서울시 강동구 강동대로 205)\\n지원분야: 보컬 / 랩 / 댄스 / 연기 / 모델\\n참여방법: 현장 접수\\n\\n주의사항\\n*신분증 반드시 준비(학생증, 여권, 등본 등) 없을 시 참여 제한\\n*보컬/랩/댄스/연기/모델 중 한 분야만 지원 가능\\n*댄스 지원자는 반드시 휴대폰 음원 지참(CD 및 USB 불가)\\n*팀 지원 가능\\n\\n여러분의 많은 참여 기다리고 있겠습니다.\\n감사합니다.\\n\\n[May, 2023 Second JYP Monthly Audition]\\n\\nDate: May 21st, 2023 (SUN)\\nTime: pm1:00~pm4:00 (No entrance after pm4:00)\\nQualification: Anyone born between 2001~2012 regardless of their gender and nationality\\nPlace: JYP Center (205, Gangdong-daero Gangdong-gu, Seoul)\\nAudition Categories: VOCAL / RAP / DANCE / ACTING / MODEL\\nHow to Apply: Walk-in Registration\\n\\nKeep in Mind\\n*You must bring your ID (ex. passport) to participate\\n*You can only apply for one audition category. (VOCAL/RAP/DANCE/ACTING/MODEL)\\n*Dance applicants must prepare their dance music on their phones. (NO physical CD or USB)\\n*You may apply as a team\\n\\nWe will be waiting for your participation!\\nThank you.\\n\\n기획사 명은? 모집 분야는? 나이에 대한 조건 중 시작 나이는? 나이에 대한 조건 중 끝 나이는? 성별 조건은? 접수 마감일은?\\r\\n\\r\\n질문에 대한 답 형식은 기획사 명 : , 분야 : , 시작 나이 : , 끝 나이 : , 성별 : , 접수 마감일 : yyyy-mm-dd로 알려줘\"]\n",
        "list_prompt = [PROMPT_DICT['prompt_no_input'].format_map({'prompt' : tmp}) for tmp in list_prompt]\n",
        "\n",
        "list_result = generator(list_prompt, **generation_args)\n",
        "for prompt, result in zip(list_prompt, list_result):\n",
        "    print(('#'*70))\n",
        "    print(('completion: %s'%(result[0]['generated_text'])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8O03d5VSGQN7",
        "outputId": "1872e5a1-d0e6-4551-d765-c441b598d056"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######################################################################\n",
            "completion: ### Instruction(명령어):\n",
            " 오디션 명 : JYP 2023년 5월 셋째주 센터오디션\n",
            "상세정보 : 2023년 5월 셋째주 센터오디션 안내\n",
            "\n",
            "접수 마감일 : 2023년 5월 21일 일요일\n",
            "시간: 오후 1시~4시 (4시 이후 입장 절대 불가)\n",
            "대상: 2001년생~2012년생 / 성별, 국적 제한 없음\n",
            "장소: JYP Center (서울시 강동구 강동대로 205)\n",
            "지원분야: 보컬 / 랩 / 댄스 / 연기 / 모델\n",
            "참여방법: 현장 접수\n",
            "\n",
            "주의사항\n",
            "*신분증 반드시 준비(학생증, 여권, 등본 등) 없을 시 참여 제한\n",
            "*보컬/랩/댄스/연기/모델 중 한 분야만 지원 가능\n",
            "*댄스 지원자는 반드시 휴대폰 음원 지참(CD 및 USB 불가)\n",
            "*팀 지원 가능\n",
            "\n",
            "여러분의 많은 참여 기다리고 있겠습니다.\n",
            "감사합니다.\n",
            "\n",
            "[May, 2023 Second JYP Monthly Audition]\n",
            "\n",
            "Date: May 21st, 2023 (SUN)\n",
            "Time: pm1:00~pm4:00 (No entrance after pm4:00)\n",
            "Qualification: Anyone born between 2001~2012 regardless of their gender and nationality\n",
            "Place: JYP Center (205, Gangdong-daero Gangdong-gu, Seoul)\n",
            "Audition Categories: VOCAL / RAP / DANCE / ACTING / MODEL\n",
            "How to Apply: Walk-in Registration\n",
            "\n",
            "Keep in Mind\n",
            "*You must bring your ID (ex. passport) to participate\n",
            "*You can only apply for one audition category. (VOCAL/RAP/DANCE/ACTING/MODEL)\n",
            "*Dance applicants must prepare their dance music on their phones. (NO physical CD or USB)\n",
            "*You may apply as a team\n",
            "\n",
            "We will be waiting for your participation!\n",
            "Thank you.\n",
            "\n",
            "기획사 명은? 모집 분야는? 나이에 대한 조건 중 시작 나이는? 나이에 대한 조건 중 끝 나이는? 성별 조건은? 접수 마감일은?\r\n",
            "\r\n",
            "질문에 대한 답 형식은 기획사 명 : , 분야 : , 시작 나이 : , 끝 나이 : , 성별 : , 접수 마감일 : yyyy-mm-dd로 알려줘 \n",
            "\n",
            "\n",
            "\n",
            " ###  Response(응답) \n",
            "기획사 명 : J YP 엔터테인먼트, 분야 : 보컬,랩,댄스,연기,모델, 시작 나이 : 2001, 끝 나이 : 2012, 성별 : 모두, 접수 마감일: 2023-5-21 완료일: 2024인의 소통을 통해 2023\n"
          ]
        }
      ]
    }
  ]
}